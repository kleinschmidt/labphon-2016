---
title: What do you expect from an unfamiliar talker?
bibliography: /Users/dkleinschmidt/Documents/papers/library-clean.bib
csl: apa.csl
output: pdf_document
geometry: margin=1in
graphics: yes
header-includes:
    - \usepackage{wrapfig}
---

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

library(supunsup)
library(dplyr)
library(tidyr)
library(magrittr)
## devtools::install_github('kleisnchmidt/daver')
library(daver)

data <- supunsup::supunsup_clean %>%
  filter(supCond == 'unsupervised') %>%
  mutate(trueCat = respCategory,
         subjNum = as.numeric(factor(subject)),
         trueCatNum = as.numeric(trueCat),
         respCatNum = as.numeric(respCat))

n_subj <- data %>% group_by(subject) %>% summarise() %>% tally()

knitr::opts_chunk$set(echo=FALSE,
                      results='hide',
                      message=FALSE,
                      warning=FALSE,
                      error=FALSE)

library(ggplot2)
theme_set(theme_bw())


```

One of the longest-standing puzzles in speech perception is how listeners cope with the often extreme differences in how individual talkers use acoustic cues to realize their linguistic intentions.  A number of solutions have been proposed, including the recent proposal that listeners quickly _adapt_ to unfamiliar talkers by _learning_ the distributions of acoustic cues that they produce (their "accent").

This can be formalized as a kind of statistical inference, where listeners try to infer which of all possible accents best explains a talker's speech [@Kleinschmidt2015]. In this view, prior experience with other talkers can help because it narrows down the range of possibilities that a listener needs to consider (in Bayesian jargon, it provides an _informative prior_ on accents). We test a critical prediction of this view: when an unfamiliar talker's accent falls _outside_ the range of typical variation across talkers, listeners should adapt only partially. Specifically, listeners' phonetic classifications should reflect a compromise between listeners' prior expectations and the actual accent they hear. We also, in doing so, demonstrate a novel technique for measuring listeners' subjective prior expectations about an unfamiliar talker's accent. Critically, this technique does not require the laborious collection and annotation of large quantities of speech from different talkers.

We use a /b/-/p/ distributional learning paradigm [@Clayards2008], where listeners ($n = `r n_subj`$) hear a bimodal distribution over voice onset time (VOT), with a cluster at a low value implicitly corresponding to /b/ and another at a high value corresponding to /p/.  By varying the location of these clusters, we create accents that are more or less like those produced by a typical American English talker [as measured by, e.g., @Kronrod2012] (Figure 1).

\begin{figure}[!h]
```{r input-vs-prior-stats, fig.width=8, fig.height=2, out.width='\\textwidth'}

## copied from NIPS paper #######################################

## prior parameters from Kronrod et al. (CogSci 2012)
prior_stats <- data.frame(category=factor(c('b', 'p')),
                          mean = c(0, 60),
                          sd = sqrt(c(14, 254)))

exposure_stats <- data %>%
  group_by(bvotCond, category=trueCat) %>%
  summarise(mean=mean(vot), sd=sd(vot))

sd_noise = sqrt(82)

stats_to_lhood <- function(stats, noise_sd=sd_noise) {
  stats %>%
    group_by(category, mean, sd) %>%
    do(data.frame(vot=seq(-30, 90, 0.5))) %>%
    ungroup() %>%
    mutate(lhood = dnorm(vot, mean, sqrt(sd^2 + noise_sd^2))) %>%
    select(-mean, -sd)
}

exposure_lhood <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(., sd_noise))

prior_lhood <- prior_stats %>% stats_to_lhood(sd_noise)

data %>%
  group_by(bvotCond, vot) %>%
  filter(subject == first(subject)) %>%
  tally() %>%
  ggplot(aes(x=vot)) +
  geom_bar(stat='identity', aes(y=n, fill=bvotCond)) +
  geom_line(data=prior_lhood, aes(y=lhood*1600, group=category),
            color="black", linetype=2) +
  geom_text(data=data.frame(bvotCond=-10), x = 10, y = 60,
            label = 'Typical Talker',
            color='black', hjust=0, vjust=0.3, size=3) +
  geom_text(data=data.frame(bvotCond=-10), x = 40, y = 50,
            label = 'Exposure\nTalker',
            color=hcl(h=15, c=100, l=65), hjust=0, vjust=0.8, size=3,
            lineheight=1) + 
  facet_grid(.~bvotCond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Frequency') +
  scale_fill_discrete('/b/ mean\nVOT') +
  theme(legend.position='none')

```
\caption{VOT distributions for each accent.}\label{fig:input-vs-prior-stats}
\end{figure}



We measure how well listeners _learn_ these accents by comparing their classification functions to the ideal boundaries implied by the exposure distributions alone (Figure 2).  As predicted, when the VOT clusters were unusually high or low, listeners _actual_ category boundaries reflected a compromise between the typical and exposure talkers.

\begin{figure}[!h]
```{r supunsup-belief-updating-qualitative, fig.height=2, fig.width=8, out.width='\\textwidth'}

## generate predicted classification functions assuming Bayes-optimal classifier
## + noise

lhood_to_classification <- function(lhood) {
  lhood %>%
    spread(category, lhood) %>%
    mutate(prob_p = p / (p+b))
}

perfect_learning <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(.)) %>%
  lhood_to_classification

no_learning <- prior_stats %>%
  stats_to_lhood %>%
  lhood_to_classification

prior_bound <- no_learning %>%
  arrange(abs(prob_p - 0.5)) %>%
  filter(row_number() ==1) %$%
  vot


boundaries <- data %>%
  group_by(bvotCond, subject) %>%
  do({ glm(respP ~ vot, family='binomial', data=.) %>%
         broom::tidy() %>%
         select(term, estimate)
  }) %>%
  ungroup() %>%
  spread(term, estimate) %>%
  mutate(boundary = -`(Intercept)` / vot,
         ideal_boundary = as.numeric(as.character(bvotCond)) + 20,
         prior_boundary = prior_bound,
         prop_shift = (boundary-prior_boundary)/(ideal_boundary-prior_boundary))

boundary_summary <- boundaries %>%
  group_by(bvotCond) %>%
  summarise(median_shift_perc = round(100*median(prop_shift)),
            shift_text = paste(median_shift_perc, '%', sep='')) %>%
  filter(bvotCond != 0)                 # basically no shift possible

ggplot(data, aes(x=vot, y=respP, color=bvotCond)) +
  geom_line(aes(group=subject), stat='smooth', method='glm', family='binomial', alpha=0.2) +
  facet_grid(.~bvotCond) +
  geom_line(data=perfect_learning, aes(y=prob_p), group=1, linetype=2, size=1) +
  geom_line(data=no_learning, aes(y=prob_p), group=1, linetype=2, color='black') +
  geom_text(data=boundary_summary, aes(x=75, y=0.1, label=shift_text), color='black') + 
  theme(legend.position='none') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Probability /p/ response') + 
  scale_color_discrete('/b/ mean\nVOT')

```
\caption{After exposure, listenersâ€™ /b/-/p/ classifications (thin colored lines; estimated via logistic GLM) reflected a compromise between the boundary for a typical talker (dashed black) and the experimental talker (dashed colored).  Moreover, more extreme shifts led to less complete adaptation (lower percentage of boundary shift from typical to experimental; not shown for 0ms shift because experimental and typical talkers are too similar to reliably measure percentage).}\label{fig:supunsup-belief-updating-qualitative}
\end{figure}

Second, we used a belief-updating model to work backwards from the patterns of adaptation to different accents, inferring what listeners' starting beliefs were (Figure 3), and how confident they were in those beliefs.  The inferred prior expectations matched the range of typical American English talkers' /b/ and /p/ distributions, including the counterintuitive finding that listeners were _more_ uncertain about the /b/ mean VOT than /p/.  Even though the _within_-talker variance of VOT is higher for /p/ than /b/, the _between_-talker variance for /b/ is likely higher because some talkers pre-voice their /b/s with large, negative mean VOTs [@Lisker1964].

The ability to measure listeners' prior expectations potentially provides an important and heretofore missing tool in the toolbox of laboratory phonology.  Measuring these beliefs is important for at least two reasons.  First, the task of learning a new talker's accent would be nearly as hard as learning the language for the first time were it not for listeners' prior experience with _other_ talkers.  Thus, understanding the remarkable ability of listeners to robustly comprehend speech from many different talkers requires understanding the expectations they bring to an unfamiliar talker.  Second, and relatedly, this technique can directly link the variability in _production_ of linguistic variables with listeners' subjective expectations about those variables, both conditioned on _social_ variables.  Our proof-of-concept here (implicitly) uses standard American English, but the same procedure can be applied to specific variables like gender, region, class, etc., by providing information to the listener about _who_ the talker is [which listeners do use to guide speech perception, @Hay2010; @Niedzielski1999; @Strand1996].


# References


\begin{wrapfigure}{r}{0.5\textwidth}
```{r inferred-prior, fig.width=4, fig.height=2, out.width='0.48\\textwidth'}

samples_to_prior_stats <- function(samples, mean_name='mu_0', sd_name='sigma_0') {
  data.frame(category = c('b', 'p'),
             mean = apply(samples[[mean_name]], 2, mean),
             sd = apply(samples[[sd_name]], 2, mean))
}

mod2_samples <- readRDS('../nips_2015/data/samples_lapsing.rds')

mod2_prior_lhood <- mod2_samples %>%
  samples_to_prior_stats %>%
  stats_to_lhood(noise_sd = 0)

ggplot(mod2_prior_lhood, aes(x=vot, y=lhood, group=category)) +
  geom_line(aes(linetype='Inferred\nprior')) +
  geom_line(data=prior_lhood, aes(linetype='Kronrod et\nal. (2012)')) +
  scale_linetype_discrete('Source') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Likelihood')

```
\caption{Cue distributions with maximum prior probability as inferred from adaptation data, compared with the distributions measured by Kronrod et al. (2012).}
\label{fig:inferred-prior}
\end{wrapfigure}
